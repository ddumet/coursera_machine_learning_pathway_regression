{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 2: Multiple Regression (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first notebook we explored multiple regression. Now we will numpy to solve for the regression weights with gradient descent.\n",
    "\n",
    "In this notebook we will cover estimating multiple regression weights via gradient descent. You will:\n",
    "* Add a constant column of 1's to a Pandas dataframe to account for the intercept\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales_dtype={'bathrooms':float, 'waterfront':int, 'sqft_above':int,\n",
    "             'sqft_living15':float, 'grade':int, 'yr_renovated':int,\n",
    "             'price':float, 'bedrooms':float, 'zipcode':str, 'long':float,\n",
    "             'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int,\n",
    "             'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str,\n",
    "             'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>101930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>101930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>6819</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>6819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>9711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>9711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>7470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5123</td>\n",
       "      <td>-122.337</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>8113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>6560</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3684</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000   221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000   538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000   180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000   604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000   510000.0       3.0       2.00       1680.0   \n",
       "5  7237550310  20140512T000000  1225000.0       4.0       4.50       5420.0   \n",
       "6  1321400060  20140627T000000   257500.0       3.0       2.25       1715.0   \n",
       "7  2008000270  20150115T000000   291850.0       3.0       1.50       1060.0   \n",
       "8  2414600126  20150415T000000   229500.0       3.0       1.00       1780.0   \n",
       "9  3793500160  20150312T000000   323000.0       3.0       2.50       1890.0   \n",
       "\n",
       "   sqft_lot floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650      1           0     0     ...          7        1180   \n",
       "1      7242      2           0     0     ...          7        2170   \n",
       "2     10000      1           0     0     ...          6         770   \n",
       "3      5000      1           0     0     ...          7        1050   \n",
       "4      8080      1           0     0     ...          8        1680   \n",
       "5    101930      1           0     0     ...         11        3890   \n",
       "6      6819      2           0     0     ...          7        1715   \n",
       "7      9711      1           0     0     ...          7        1060   \n",
       "8      7470      1           0     0     ...          7        1050   \n",
       "9      6560      2           0     0     ...          7        1890   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "5           1530      2001             0    98053  47.6561 -122.005   \n",
       "6              0      1995             0    98003  47.3097 -122.327   \n",
       "7              0      1963             0    98198  47.4095 -122.315   \n",
       "8            730      1960             0    98146  47.5123 -122.337   \n",
       "9              0      2003             0    98038  47.3684 -122.031   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1340.0      5650.0  \n",
       "1         1690.0      7639.0  \n",
       "2         2720.0      8062.0  \n",
       "3         1360.0      5000.0  \n",
       "4         1800.0      7503.0  \n",
       "5         4760.0    101930.0  \n",
       "6         2238.0      6819.0  \n",
       "7         1650.0      9711.0  \n",
       "8         1780.0      8113.0  \n",
       "9         2390.0      7570.0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(\"./data/kc_house_data.csv\", dtype=sales_dtype)\n",
    "sales.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that will accept a Pandas DataFrame, a list of feature names (e.g. ['sqft_living', 'bedrooms']) and a target feature e.g. ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function (where there's an empty line you should write a line of code that does what the comment above indicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    nb_observations = data_frame.shape[0]\n",
    "    feature_matrix = np.concatenate((np.ones((nb_observations,1)),data_frame.as_matrix(columns=features)),axis=1)\n",
    "    output_array = data_frame.as_matrix(columns=output)\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.18000000e+03]\n",
      "[ 221900.]\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, [\"sqft_living\"], [\"price\"])\n",
    "print(example_features[0,:])\n",
    "print(example_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] both **column vectors** and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 this is the dot product between these two arrays. That is:\n",
    "\n",
    "$y_i = w^T*h_i$\n",
    "\n",
    "$y_i$ is then a **scalar**.\n",
    "\n",
    "If they're numpy arrays we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value: [[ 1181.]]\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([[1.],[1.]]) # the example weights as COLUMN VECTOR\n",
    "my_features = (example_features[0,]).reshape(2,1) # we'll use the first data point as COLUMN VECTOR\n",
    "\n",
    "predicted_value = np.dot(np.transpose(my_weights),my_features)\n",
    "print(\"predicted value:\",predicted_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot() also works when dealing with a matrix and a vector. Recall that the predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features **matrix** $H$ and the weights **column vector** $w$. That is:\n",
    "\n",
    "$y = H *w$\n",
    "\n",
    "$y$ is then a **vector**.\n",
    "\n",
    "With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):   \n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test your code run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1181.]\n",
      "[ 2571.]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print(test_predictions[0]) # should be 1181.0\n",
    "print(test_predictions[1]) # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "**(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2**\n",
    "\n",
    "Where we have **k** features and a constant. So the derivative with respect to weight **w[i]** by the chain rule is:\n",
    "\n",
    "**2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]**\n",
    "\n",
    "The term inside the paranthesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "**2\\*error\\*[feature_i]**\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Derivative (using Matrix representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the above, let's use the Matrix representation:\n",
    "\n",
    "\n",
    "$\\bigtriangledown RSS = 2*H^T*(y - Hw)$\n",
    "\n",
    "with $(y - Hw)$ being the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we are calculating here is not the **derivative** but the **gradient**!\n",
    "\n",
    "We keep the function name same as in the original notebook though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    \n",
    "    gradient = 2*np.dot(np.transpose(feature), errors)\n",
    "\n",
    "    return(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your feature derivartive run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.33458500e+10]]\n",
      "-23345850016.0\n"
     ]
    }
   ],
   "source": [
    "# get features matrix and vector output\n",
    "(example_features, example_output) = get_numpy_data(sales, [\"sqft_living\"], [\"price\"]) \n",
    "\n",
    "# Set weights vector to 0 (this will make all predictions = 0)\n",
    "# Set weights as a column vector due to how we've defined the feature_derivative function\n",
    "# i.e. using Matrix representation\n",
    "# This is different from the class notebook where my_weights is defined as: my_weights = np.array([0., 0.])\n",
    "my_weights = np.array([[0.],[0.]])\n",
    "\n",
    "# get predictions y_predict\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "\n",
    "# Get the errors (will be allow -example_output as test_predictions = 0!)\n",
    "errors = test_predictions - example_output\n",
    "\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature.reshape(feature.shape[0],1))\n",
    "print(derivative)\n",
    "print(-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "**The magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)**\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent (using Matrix representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here also let's use the Matrix representation for the gradient descent, that is:\n",
    "\n",
    "$w^{(t+1)} = w^{(t)} -\\eta * \\bigtriangledown RSS$\n",
    "\n",
    "or:\n",
    "\n",
    "$w^{(t+1)} = w^{(t)} -\\eta * 2*H^T*(y - Hw)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix,weights)\n",
    "\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        \n",
    "        # compute gradient of RSS\n",
    "        gradient = feature_derivative(errors, feature_matrix)\n",
    "        \n",
    "        # update weights\n",
    "        weights = weights - step_size*gradient\n",
    "        \n",
    "        gradient_magnitude = sqrt(np.square(gradient).sum())\n",
    "\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/kc_house_train_data.csv\", dtype=sales_dtype)\n",
    "test_data = pd.read_csv(\"./data/kc_house_test_data.csv\", dtype=sales_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Gradient Descent\n",
    "Although the gradient descent is designed for multiple regression since the constant is now a feature we can use the gradient descent function to estimat the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_features = [\"sqft_living\"]\n",
    "my_output = [\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "(model_1_feature_matrix, output) = get_numpy_data(train_data, model_1_features, my_output)\n",
    "initial_weights = np.array([[-47000.],[1.]])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1_weights = regression_gradient_descent(model_1_feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1_weights: [[-46999.88716555]\n",
      " [   281.91211918]]\n"
     ]
    }
   ],
   "source": [
    "print(\"model_1_weights:\",model_1_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights are close to the one found in week_1. Values from week_1 were:\n",
    "- Intercept: -47116.07907289418\n",
    "- Slope: 281.9588396303426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of the weight for sqft_living: 281.9\n"
     ]
    }
   ],
   "source": [
    "print(\"value of the weight for sqft_living:\",round(model_1_weights[1,0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with the determined weights\n",
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(model_1_test_feature_matrix, test_output) = get_numpy_data(test_data, model_1_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_test_predictions = predict_output(model_1_test_feature_matrix, model_1_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted price for the first house: 356134.0\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted price for the first house:\",round(model_1_test_predictions[0,0],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS_model_1_test: 2.75400044902e+14\n"
     ]
    }
   ],
   "source": [
    "RSS_model_1_test = (np.square(test_output - model_1_test_predictions).sum())\n",
    "print(\"RSS_model_1_test:\",RSS_model_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Gradient Descent\n",
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_features = [\"sqft_living\",\"sqft_living15\"] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = [\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(model_2_feature_matrix, output) = get_numpy_data(train_data, model_2_features, my_output)\n",
    "initial_weights = np.array([[-100000.],[1.],[1.]])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above parameters to estimate the model weights. Record these values for your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_2_weights = regression_gradient_descent(model_2_feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_2_weights: [[ -9.99999688e+04]\n",
      " [  2.45072603e+02]\n",
      " [  6.52795267e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"model_2_weights:\",model_2_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with the determined weights\n",
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(model_2_test_feature_matrix, test_output) = get_numpy_data(test_data, model_2_features, my_output)\n",
    "model_2_test_predictions = predict_output(model_2_test_feature_matrix, model_2_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted price for the first house: 366651.0\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted price for the first house:\",round(model_2_test_predictions[0,0],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual price for the 1st house in the test data set: 310000.0\n"
     ]
    }
   ],
   "source": [
    "print(\"actual price for the 1st house in the test data set:\", round(test_output[0,0],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which estimate was closer to the true price for the 1st house on the Test data set, model 1 or model 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between model_1 prediction and true price: -46134.0\n",
      "distance between model_2 prediction and true price: -56651.0\n"
     ]
    }
   ],
   "source": [
    "print(\"distance between model_1 prediction and true price:\",\n",
    "      round(test_output[0,0] - model_1_test_predictions[0,0],0))\n",
    "print(\"distance between model_2 prediction and true price:\",\n",
    "      round(test_output[0,0] - model_2_test_predictions[0,0],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_1 is **closer** for 1st house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS_model_2_test: 2.7026344363e+14\n"
     ]
    }
   ],
   "source": [
    "RSS_model_2_test = (np.square(test_output - model_2_test_predictions).sum())\n",
    "print(\"RSS_model_2_test:\",RSS_model_2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS_model_2_test < RSS_model_1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 has the lowest RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
